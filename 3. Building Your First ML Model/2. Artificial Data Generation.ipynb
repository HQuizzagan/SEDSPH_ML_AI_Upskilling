{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setting Up the Environment**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458644, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./nyc-taxi-trip-duration/train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1275084</th>\n",
       "      <td>id1316218</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-17 04:02:28</td>\n",
       "      <td>2016-06-17 04:14:18</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987709</td>\n",
       "      <td>40.721054</td>\n",
       "      <td>-73.954971</td>\n",
       "      <td>40.745071</td>\n",
       "      <td>N</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175063</th>\n",
       "      <td>id2752282</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-15 06:52:23</td>\n",
       "      <td>2016-06-15 07:08:02</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990303</td>\n",
       "      <td>40.771835</td>\n",
       "      <td>-74.013542</td>\n",
       "      <td>40.715569</td>\n",
       "      <td>N</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011320</th>\n",
       "      <td>id2449794</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-17 20:29:36</td>\n",
       "      <td>2016-01-17 20:39:08</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.862442</td>\n",
       "      <td>40.770126</td>\n",
       "      <td>-73.921120</td>\n",
       "      <td>40.774483</td>\n",
       "      <td>N</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605947</th>\n",
       "      <td>id0798317</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-06 18:39:16</td>\n",
       "      <td>2016-02-06 18:53:16</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.986832</td>\n",
       "      <td>40.768494</td>\n",
       "      <td>-73.987999</td>\n",
       "      <td>40.750748</td>\n",
       "      <td>N</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741247</th>\n",
       "      <td>id0091968</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-09 20:40:44</td>\n",
       "      <td>2016-03-09 21:01:59</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.954933</td>\n",
       "      <td>40.773376</td>\n",
       "      <td>-73.996521</td>\n",
       "      <td>40.727024</td>\n",
       "      <td>N</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125815</th>\n",
       "      <td>id1215018</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-20 19:00:59</td>\n",
       "      <td>2016-03-20 19:14:06</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.000900</td>\n",
       "      <td>40.720669</td>\n",
       "      <td>-74.005089</td>\n",
       "      <td>40.735939</td>\n",
       "      <td>N</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212015</th>\n",
       "      <td>id3399275</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-27 08:36:27</td>\n",
       "      <td>2016-06-27 08:42:25</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.969810</td>\n",
       "      <td>40.756878</td>\n",
       "      <td>-73.955315</td>\n",
       "      <td>40.764648</td>\n",
       "      <td>N</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029101</th>\n",
       "      <td>id1216442</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-23 17:13:20</td>\n",
       "      <td>2016-04-23 17:25:28</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.978012</td>\n",
       "      <td>40.758591</td>\n",
       "      <td>-73.984802</td>\n",
       "      <td>40.760529</td>\n",
       "      <td>N</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428182</th>\n",
       "      <td>id1047230</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-15 11:35:11</td>\n",
       "      <td>2016-01-15 11:36:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.995285</td>\n",
       "      <td>40.744831</td>\n",
       "      <td>-73.999329</td>\n",
       "      <td>40.738987</td>\n",
       "      <td>N</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264061</th>\n",
       "      <td>id3519038</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-10 13:46:40</td>\n",
       "      <td>2016-02-10 13:49:33</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.003838</td>\n",
       "      <td>40.726406</td>\n",
       "      <td>-74.004524</td>\n",
       "      <td>40.732712</td>\n",
       "      <td>N</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "1275084  id1316218          1  2016-06-17 04:02:28  2016-06-17 04:14:18   \n",
       "175063   id2752282          2  2016-06-15 06:52:23  2016-06-15 07:08:02   \n",
       "1011320  id2449794          1  2016-01-17 20:29:36  2016-01-17 20:39:08   \n",
       "605947   id0798317          1  2016-02-06 18:39:16  2016-02-06 18:53:16   \n",
       "741247   id0091968          1  2016-03-09 20:40:44  2016-03-09 21:01:59   \n",
       "1125815  id1215018          1  2016-03-20 19:00:59  2016-03-20 19:14:06   \n",
       "212015   id3399275          1  2016-06-27 08:36:27  2016-06-27 08:42:25   \n",
       "1029101  id1216442          2  2016-04-23 17:13:20  2016-04-23 17:25:28   \n",
       "1428182  id1047230          1  2016-01-15 11:35:11  2016-01-15 11:36:40   \n",
       "1264061  id3519038          1  2016-02-10 13:46:40  2016-02-10 13:49:33   \n",
       "\n",
       "         passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "1275084                1        -73.987709        40.721054   \n",
       "175063                 1        -73.990303        40.771835   \n",
       "1011320                1        -73.862442        40.770126   \n",
       "605947                 3        -73.986832        40.768494   \n",
       "741247                 2        -73.954933        40.773376   \n",
       "1125815                1        -74.000900        40.720669   \n",
       "212015                 1        -73.969810        40.756878   \n",
       "1029101                1        -73.978012        40.758591   \n",
       "1428182                1        -73.995285        40.744831   \n",
       "1264061                1        -74.003838        40.726406   \n",
       "\n",
       "         dropoff_longitude  dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "1275084         -73.954971         40.745071                  N            710  \n",
       "175063          -74.013542         40.715569                  N            939  \n",
       "1011320         -73.921120         40.774483                  N            572  \n",
       "605947          -73.987999         40.750748                  N            840  \n",
       "741247          -73.996521         40.727024                  N           1275  \n",
       "1125815         -74.005089         40.735939                  N            787  \n",
       "212015          -73.955315         40.764648                  N            358  \n",
       "1029101         -73.984802         40.760529                  N            728  \n",
       "1428182         -73.999329         40.738987                  N             89  \n",
       "1264061         -74.004524         40.732712                  N            173  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a random 10 rows\n",
    "df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Data Generation\n",
    "To simulate dirty data, we will add more records to the data such that\n",
    "- there will be missing values\n",
    "- some of the values might not be in the right format or data type such as a number stored as a string\n",
    "- there are duplicates in the data\n",
    "- outliers exist\n",
    "- non-normalized values (i.e. values that are not in the same scale) or non-standardized values (i.e. values that are not in the same range)\n",
    "- multi-collinearity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Add new records which is 10% of the original dataset but with missing values\n",
    "def simulateMissingVals(df, pctEmpty=10):\n",
    "    num_missing_rows = int(df.shape[0] * pctEmpty / 100)\n",
    "    \n",
    "    # Create the new records\n",
    "    new_records = df.sample(num_missing_rows, replace=False)\n",
    "    \n",
    "    # Randomly select one/more of the columns to set as np.nan\n",
    "    for i in tqdm(new_records.index, desc=\"Progress\", unit=\"item\"):\n",
    "        num_empty_cols = np.random.randint(1, df.shape[1]+1)\n",
    "        empty_cols = np.random.choice(df.columns, num_empty_cols, replace=False)\n",
    "        new_records.loc[i, empty_cols] = np.nan\n",
    "    \n",
    "    # Append the new records to the original dataframe and place them randomly in the new dataframe\n",
    "    df = df.append(new_records)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 218796/218796 [09:36<00:00, 379.38item/s]\n",
      "/var/folders/3k/8x521n3x1hv89v96qvzcfzb00000gn/T/ipykernel_2693/2312774374.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_records)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1458644, 11), (1677440, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = simulateMissingVals(df, pctEmpty=15)\n",
    "\n",
    "df.shape, df_dirty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dirty dataset\n",
    "df_dirty.to_csv('./nyc-taxi-trip-duration/train_dirty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    119576\n",
       "vendor_id             119548\n",
       "pickup_datetime       119744\n",
       "dropoff_datetime      119455\n",
       "passenger_count       119274\n",
       "pickup_longitude      119424\n",
       "pickup_latitude       119951\n",
       "dropoff_longitude     119995\n",
       "dropoff_latitude      119616\n",
       "store_and_fwd_flag    119431\n",
       "trip_duration         119676\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the latest dirty dataset\n",
    "df_dirty = pd.read_csv('./nyc-taxi-trip-duration/train_dirty.csv')\n",
    "\n",
    "df_dirty.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.557892e+06</td>\n",
       "      <td>1.558166e+06</td>\n",
       "      <td>1.558016e+06</td>\n",
       "      <td>1.557489e+06</td>\n",
       "      <td>1.557445e+06</td>\n",
       "      <td>1.557824e+06</td>\n",
       "      <td>1.557764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.534895e+00</td>\n",
       "      <td>1.664459e+00</td>\n",
       "      <td>-7.397349e+01</td>\n",
       "      <td>4.075092e+01</td>\n",
       "      <td>-7.397340e+01</td>\n",
       "      <td>4.075181e+01</td>\n",
       "      <td>9.591557e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.987810e-01</td>\n",
       "      <td>1.313983e+00</td>\n",
       "      <td>6.935497e-02</td>\n",
       "      <td>3.266136e-02</td>\n",
       "      <td>6.914012e-02</td>\n",
       "      <td>3.600310e-02</td>\n",
       "      <td>5.130668e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.219333e+02</td>\n",
       "      <td>3.435970e+01</td>\n",
       "      <td>-1.219333e+02</td>\n",
       "      <td>3.218114e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.399187e+01</td>\n",
       "      <td>4.073736e+01</td>\n",
       "      <td>-7.399133e+01</td>\n",
       "      <td>4.073589e+01</td>\n",
       "      <td>3.970000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.398174e+01</td>\n",
       "      <td>4.075409e+01</td>\n",
       "      <td>-7.397974e+01</td>\n",
       "      <td>4.075453e+01</td>\n",
       "      <td>6.620000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-7.396733e+01</td>\n",
       "      <td>4.076835e+01</td>\n",
       "      <td>-7.396300e+01</td>\n",
       "      <td>4.076981e+01</td>\n",
       "      <td>1.075000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>-6.133553e+01</td>\n",
       "      <td>5.188108e+01</td>\n",
       "      <td>-6.133553e+01</td>\n",
       "      <td>4.392103e+01</td>\n",
       "      <td>3.526282e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "count  1.557892e+06     1.558166e+06      1.558016e+06     1.557489e+06   \n",
       "mean   1.534895e+00     1.664459e+00     -7.397349e+01     4.075092e+01   \n",
       "std    4.987810e-01     1.313983e+00      6.935497e-02     3.266136e-02   \n",
       "min    1.000000e+00     0.000000e+00     -1.219333e+02     3.435970e+01   \n",
       "25%    1.000000e+00     1.000000e+00     -7.399187e+01     4.073736e+01   \n",
       "50%    2.000000e+00     1.000000e+00     -7.398174e+01     4.075409e+01   \n",
       "75%    2.000000e+00     2.000000e+00     -7.396733e+01     4.076835e+01   \n",
       "max    2.000000e+00     9.000000e+00     -6.133553e+01     5.188108e+01   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  trip_duration  \n",
       "count       1.557445e+06      1.557824e+06   1.557764e+06  \n",
       "mean       -7.397340e+01      4.075181e+01   9.591557e+02  \n",
       "std         6.914012e-02      3.600310e-02   5.130668e+03  \n",
       "min        -1.219333e+02      3.218114e+01   1.000000e+00  \n",
       "25%        -7.399133e+01      4.073589e+01   3.970000e+02  \n",
       "50%        -7.397974e+01      4.075453e+01   6.620000e+02  \n",
       "75%        -7.396300e+01      4.076981e+01   1.075000e+03  \n",
       "max        -6.133553e+01      4.392103e+01   3.526282e+06  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     object\n",
       "vendor_id             float64\n",
       "pickup_datetime        object\n",
       "dropoff_datetime       object\n",
       "passenger_count       float64\n",
       "pickup_longitude      float64\n",
       "pickup_latitude       float64\n",
       "dropoff_longitude     float64\n",
       "dropoff_latitude      float64\n",
       "store_and_fwd_flag     object\n",
       "trip_duration         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatypes of each column\n",
    "df_dirty.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical variables are: ['id', 'pickup_datetime', 'dropoff_datetime', 'store_and_fwd_flag']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['N', nan, 'Y'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract categorical variables\n",
    "cat_vars = [col for col in df_dirty.columns if df_dirty[col].dtype == 'object']\n",
    "print(f'The categorical variables are: {cat_vars}')\n",
    "\n",
    "# Check the unique values for the CATEGORICAL VARIABLES\n",
    "df_dirty['store_and_fwd_flag'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are **very few** CATEGORICAL VARIABLES in the dataset, let's artificaially create some categorical variables relevant to the context of the dataset: taxi trip dataset in NYC. Some examples of categorical variables that we can create are:\n",
    "- boroughs\n",
    "- neighborhoods\n",
    "- taxi types\n",
    "- payment types\n",
    "- weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some new CATEGORICAL VARIABLES: NYC borough, taxi types, and payment types\n",
    "NYC_BOROUGHS = ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island']\n",
    "TAXI_TYPES = ['yellow', 'green', 'fhv']\n",
    "PAYMENT_TYPES = ['cash', 'credit', 'no charge', 'dispute', 'unknown', 'voided trip']\n",
    "\n",
    "# Create the categorical columns\n",
    "df_dirty['nyc_borough'] = np.random.choice(NYC_BOROUGHS, df_dirty.shape[0])\n",
    "df_dirty['taxi_type'] = np.random.choice(TAXI_TYPES, df_dirty.shape[0])\n",
    "df_dirty['payment_type'] = np.random.choice(PAYMENT_TYPES, df_dirty.shape[0])\n",
    "\n",
    "# Save the dirty dataset\n",
    "df_dirty.to_csv('./nyc-taxi-trip-duration/train_dirty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    119576\n",
       "vendor_id             119548\n",
       "pickup_datetime       119744\n",
       "dropoff_datetime      119455\n",
       "passenger_count       119274\n",
       "pickup_longitude      119424\n",
       "pickup_latitude       119951\n",
       "dropoff_longitude     119995\n",
       "dropoff_latitude      119616\n",
       "store_and_fwd_flag    119431\n",
       "trip_duration         119676\n",
       "nyc_borough                0\n",
       "taxi_type                  0\n",
       "payment_type               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the dirty dataset\n",
    "df_dirty = pd.read_csv('./nyc-taxi-trip-duration/train_dirty.csv')\n",
    "\n",
    "df_dirty.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     object\n",
       "vendor_id             float64\n",
       "pickup_datetime        object\n",
       "dropoff_datetime       object\n",
       "passenger_count       float64\n",
       "pickup_longitude      float64\n",
       "pickup_latitude       float64\n",
       "dropoff_longitude     float64\n",
       "dropoff_latitude      float64\n",
       "store_and_fwd_flag     object\n",
       "trip_duration         float64\n",
       "nyc_borough            object\n",
       "taxi_type              object\n",
       "payment_type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    119576\n",
       "vendor_id             119548\n",
       "pickup_datetime       119744\n",
       "dropoff_datetime      119455\n",
       "passenger_count       119274\n",
       "pickup_longitude      119424\n",
       "pickup_latitude       119951\n",
       "dropoff_longitude     119995\n",
       "dropoff_latitude      119616\n",
       "store_and_fwd_flag    119431\n",
       "trip_duration         119676\n",
       "nyc_borough           561366\n",
       "taxi_type             405660\n",
       "payment_type          700956\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each of the three columns, randomly select a random number of rows to set as np.nan\n",
    "for col in ['nyc_borough', 'taxi_type', 'payment_type']:\n",
    "    num_missing_rows = np.random.randint(1, df_dirty.shape[0]+1)\n",
    "    missing_rows = np.random.choice(df_dirty.index, num_missing_rows, replace=False)\n",
    "    df_dirty.loc[missing_rows, col] = np.nan\n",
    "    \n",
    "# Save the dirty dataset\n",
    "df_dirty.to_csv('./nyc-taxi-trip-duration/train_dirty.csv', index=False)\n",
    "\n",
    "df_dirty.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates and Outliers\n",
    "\n",
    "Let's create random duplicates and outliers in the dataset, to simulate dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677440, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = pd.read_csv('./nyc-taxi-trip-duration/train_dirty.csv')\n",
    "df_dirty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicateRecords(df):\n",
    "    print(f'Original: {df.shape[0]:,}')\n",
    "    \n",
    "    # Create a new dataframe with duplicate records\n",
    "    random_pct = np.random.random() # Duplicate less than 1% of the original dataset\n",
    "    print(f'Duplicating {random_pct:,.2}% of the original dataset ...')\n",
    "    df_dup = df.sample(frac=random_pct/100, replace=True)\n",
    "    \n",
    "    # Append the new dataframe to the original dataframe\n",
    "    df = pd.concat([df, df_dup], axis=0)\n",
    "    \n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    print(f'After duplication: {df.shape[0]:,}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1,677,440\n",
      "Duplicating 0.66% of the original dataset ...\n",
      "After duplication: 1,688,528\n"
     ]
    }
   ],
   "source": [
    "df_dirty = duplicateRecords(df_dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of duplicate records\n",
    "df_dirty.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outliers to the dataset\n",
    "def addOutliers(df):\n",
    "    print(f'Original: {df.shape[0]:,}')\n",
    "    \n",
    "    # Create a new dataframe with outliers\n",
    "    random_pct = np.random.random() # Add outliers to less than 1% of the original dataset\n",
    "    print(f'Adding outliers to {random_pct:,.2}% of the original dataset ...')\n",
    "    \n",
    "    # Randomly select records from the dataset\n",
    "    df_outliers = df.sample(frac=random_pct/100, replace=True)\n",
    "    \n",
    "    # Replace the values of the selected records with outliers for the following columns\n",
    "    for col in ['passenger_count', 'trip_duration']:\n",
    "        df_outliers[col] = df_outliers[col] * np.random.randint(1000, 10_000)\n",
    "    \n",
    "    # Append the new dataframe to the original dataframe\n",
    "    df = pd.concat([df, df_outliers], axis=0)\n",
    "    \n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    print(f'After adding outliers: {df.shape[0]:,}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1,688,528\n",
      "Adding outliers to 0.11% of the original dataset ...\n",
      "After adding outliers: 1,690,302\n"
     ]
    }
   ],
   "source": [
    "# Simulate outliers\n",
    "df_dirty = addOutliers(df_dirty)\n",
    "\n",
    "# Save the dirty dataset\n",
    "df_dirty.to_csv('./nyc-taxi-trip-duration/train_dirty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.570180e+06</td>\n",
       "      <td>1.569723e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.121235e+01</td>\n",
       "      <td>5.823368e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.720397e+02</td>\n",
       "      <td>4.270312e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.970000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.630000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.077000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.252600e+04</td>\n",
       "      <td>4.274672e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_count  trip_duration\n",
       "count     1.570180e+06   1.569723e+06\n",
       "mean      1.121235e+01   5.823368e+03\n",
       "std       3.720397e+02   4.270312e+05\n",
       "min       0.000000e+00   1.000000e+00\n",
       "25%       1.000000e+00   3.970000e+02\n",
       "50%       1.000000e+00   6.630000e+02\n",
       "75%       2.000000e+00   1.077000e+03\n",
       "max       3.252600e+04   4.274672e+08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty[['passenger_count', 'trip_duration']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Normalized and Non-Standardized Values\n",
    "\n",
    "No need to artifically simulate this. Note that\n",
    "- normalization - useful when a feature has a strict upper and lower bound, while\n",
    "- standardization - useful when a feature has no strict upper and lower bound but is assumed to be normally distributed (i.e. Gaussian distribution)\n",
    "\n",
    "In our existing dataset,\n",
    "- `passenger_count` has a strict upper bound of 3 passengers as that's the only number of passengers that can fit in a sedan taxi\n",
    "- `trip_distance` has no strict upper and lower bound but is assumed to be normally distributed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-collinearity\n",
    "\n",
    "This is an often overlooked problem in data science. Multi-collinearity is when two or more features are highly correlated with each other. This is a problem because it makes it difficult for the model to distinguish between the effects of the two features on the target variable. In other words, the model will not be able to tell which feature is causing the change in the target variable.\n",
    "\n",
    "In order to simulate this, let's create a new feature `trip_distance_km` that is the same as `trip_distance` but in kilometers instead of miles. This will create a perfect correlation between the two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1690302, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = pd.read_csv(\"./nyc-taxi-trip-duration/train_dirty.csv\")\n",
    "df_dirty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'dropoff_datetime',\n",
       "       'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
       "       'trip_duration', 'nyc_borough', 'taxi_type', 'payment_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between the pickup and dropoff locations\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6371 # Radius of the Earth in km\n",
    "    \n",
    "    # Convert latitude and longitude to radians\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi       = np.radians(lat2 - lat1)\n",
    "    dlambda    = np.radians(lon2 - lon1)\n",
    "    \n",
    "    a = np.sin(dphi/2)**2 + \\\n",
    "        np.cos(phi1) * np.cos(phi2) * np.sin(dlambda/2)**2\n",
    "    \n",
    "    return 2*r*np.arctan2(np.sqrt(a), np.sqrt(1 - a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1690302, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the distance between the pickup and dropoff locations\n",
    "df_dirty['distance'] = haversine_distance(df_dirty['pickup_latitude'], df_dirty['pickup_longitude'], df_dirty['dropoff_latitude'], df_dirty['dropoff_longitude'])\n",
    "\n",
    "df_dirty['speed'] = df_dirty['distance'] / df_dirty['trip_duration'] * 3600\n",
    "\n",
    "df_dirty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>nyc_borough</th>\n",
       "      <th>taxi_type</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1115363</th>\n",
       "      <td>id2753458</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-03-30 20:27:47</td>\n",
       "      <td>2016-03-30 21:01:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-74.005203</td>\n",
       "      <td>40.728809</td>\n",
       "      <td>-73.960663</td>\n",
       "      <td>40.659550</td>\n",
       "      <td>N</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.568035</td>\n",
       "      <td>15.194545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650989</th>\n",
       "      <td>id2556201</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-12 05:21:18</td>\n",
       "      <td>2016-01-12 05:40:15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.992889</td>\n",
       "      <td>40.747791</td>\n",
       "      <td>-73.942833</td>\n",
       "      <td>40.702301</td>\n",
       "      <td>N</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>voided trip</td>\n",
       "      <td>6.586314</td>\n",
       "      <td>20.853764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404363</th>\n",
       "      <td>id3862406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-11 02:49:00</td>\n",
       "      <td>2016-05-11 03:07:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.983856</td>\n",
       "      <td>40.749092</td>\n",
       "      <td>-73.940125</td>\n",
       "      <td>40.835163</td>\n",
       "      <td>N</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>fhv</td>\n",
       "      <td>no charge</td>\n",
       "      <td>10.254318</td>\n",
       "      <td>33.347374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "1115363  id2753458        2.0  2016-03-30 20:27:47  2016-03-30 21:01:37   \n",
       "650989   id2556201        2.0  2016-01-12 05:21:18  2016-01-12 05:40:15   \n",
       "1404363  id3862406        1.0  2016-05-11 02:49:00  2016-05-11 03:07:27   \n",
       "\n",
       "         passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "1115363              1.0        -74.005203        40.728809   \n",
       "650989               1.0        -73.992889        40.747791   \n",
       "1404363              1.0        -73.983856        40.749092   \n",
       "\n",
       "         dropoff_longitude  dropoff_latitude store_and_fwd_flag  \\\n",
       "1115363         -73.960663         40.659550                  N   \n",
       "650989          -73.942833         40.702301                  N   \n",
       "1404363         -73.940125         40.835163                  N   \n",
       "\n",
       "         trip_duration nyc_borough taxi_type payment_type   distance  \\\n",
       "1115363         2030.0      Queens       NaN          NaN   8.568035   \n",
       "650989          1137.0    Brooklyn       NaN  voided trip   6.586314   \n",
       "1404363         1107.0   Manhattan       fhv    no charge  10.254318   \n",
       "\n",
       "             speed  \n",
       "1115363  15.194545  \n",
       "650989   20.853764  \n",
       "1404363  33.347374  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multi-collinearity by generating trip_distance_miles\n",
    "df_dirty['trip_distance_miles'] = df_dirty['distance'] * 0.621371\n",
    "\n",
    "# Simulate multi-collinearity by generating trip_duration_minutes\n",
    "df_dirty['trip_duration_minutes'] = df_dirty['trip_duration'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>nyc_borough</th>\n",
       "      <th>taxi_type</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>speed</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>trip_duration_minutes</th>\n",
       "      <th>LC_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104623</th>\n",
       "      <td>id3009824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-30 18:01:56</td>\n",
       "      <td>2016-05-30 18:11:55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-73.992188</td>\n",
       "      <td>40.723923</td>\n",
       "      <td>-73.976303</td>\n",
       "      <td>40.725338</td>\n",
       "      <td>N</td>\n",
       "      <td>599.0</td>\n",
       "      <td>Queens</td>\n",
       "      <td>yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.347789</td>\n",
       "      <td>8.100237</td>\n",
       "      <td>0.837477</td>\n",
       "      <td>9.983333</td>\n",
       "      <td>26.694311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203065</th>\n",
       "      <td>id3864038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-12 00:29:28</td>\n",
       "      <td>2016-01-12 00:59:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-73.776726</td>\n",
       "      <td>40.645329</td>\n",
       "      <td>-73.986092</td>\n",
       "      <td>40.758202</td>\n",
       "      <td>N</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>fhv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.656866</td>\n",
       "      <td>43.074430</td>\n",
       "      <td>13.456949</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>91.588615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215359</th>\n",
       "      <td>id0132066</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-04-03 18:04:15</td>\n",
       "      <td>2016-04-03 18:22:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.863525</td>\n",
       "      <td>40.769775</td>\n",
       "      <td>-73.964134</td>\n",
       "      <td>40.755394</td>\n",
       "      <td>N</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>green</td>\n",
       "      <td>cash</td>\n",
       "      <td>8.622997</td>\n",
       "      <td>28.531977</td>\n",
       "      <td>5.358081</td>\n",
       "      <td>18.133333</td>\n",
       "      <td>52.323414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "104623   id3009824        1.0  2016-05-30 18:01:56  2016-05-30 18:11:55   \n",
       "1203065  id3864038        2.0  2016-01-12 00:29:28  2016-01-12 00:59:38   \n",
       "215359   id0132066        2.0  2016-04-03 18:04:15  2016-04-03 18:22:23   \n",
       "\n",
       "         passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "104623               3.0        -73.992188        40.723923   \n",
       "1203065              2.0        -73.776726        40.645329   \n",
       "215359               1.0        -73.863525        40.769775   \n",
       "\n",
       "         dropoff_longitude  dropoff_latitude store_and_fwd_flag  \\\n",
       "104623          -73.976303         40.725338                  N   \n",
       "1203065         -73.986092         40.758202                  N   \n",
       "215359          -73.964134         40.755394                  N   \n",
       "\n",
       "         trip_duration nyc_borough taxi_type payment_type   distance  \\\n",
       "104623           599.0      Queens    yellow          NaN   1.347789   \n",
       "1203065         1810.0    Brooklyn       fhv          NaN  21.656866   \n",
       "215359          1088.0       Bronx     green         cash   8.622997   \n",
       "\n",
       "             speed  trip_distance_miles  trip_duration_minutes     LC_sim  \n",
       "104623    8.100237             0.837477               9.983333  26.694311  \n",
       "1203065  43.074430            13.456949              30.166667  91.588615  \n",
       "215359   28.531977             5.358081              18.133333  52.323414  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate multi-collinearity with a linear combination of 3 random variables from the numerical columns\n",
    "random_cols = np.random.choice(['passenger_count', 'trip_duration', 'distance', 'speed', 'trip_duration_minutes', 'trip_distance_miles'], 3, replace=False)\n",
    "df_dirty['LC_sim'] = df_dirty[random_cols[0]] + 0.34 * df_dirty[random_cols[1]] + 0.12 * df_dirty[random_cols[2]]/3.2\n",
    "\n",
    "# Save the dirty dataset\n",
    "df_dirty.to_csv('./nyc-taxi-trip-duration/train_dirty.csv', index=False)\n",
    "\n",
    "df_dirty.sample(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
